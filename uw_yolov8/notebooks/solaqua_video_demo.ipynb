{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ba8de9c",
   "metadata": {},
   "source": [
    "# Dataset Extraction\n",
    "\n",
    "This is a notebook for getting started with the data.\n",
    "\n",
    "The dataset used is **SOLAQUA**, available from [SINTEF Open Data](https://data.sintef.no/feature/fe-a8f86232-5107-495e-a3dd-a86460eebef6).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc46e482",
   "metadata": {},
   "source": [
    "## Installing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84d5260c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rosbags\n",
      "  Downloading rosbags-0.9.23-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting lz4 (from rosbags)\n",
      "  Downloading lz4-4.4.5-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: numpy in /cluster/home/henrban/SOLAQUA-UOD/.venv/lib/python3.9/site-packages (from rosbags) (2.0.2)\n",
      "Collecting ruamel.yaml (from rosbags)\n",
      "  Downloading ruamel.yaml-0.18.16-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting zstandard (from rosbags)\n",
      "  Downloading zstandard-0.25.0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml->rosbags)\n",
      "  Downloading ruamel.yaml.clib-0.2.14-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Downloading rosbags-0.9.23-py3-none-any.whl (102 kB)\n",
      "Downloading lz4-4.4.5-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ruamel.yaml-0.18.16-py3-none-any.whl (119 kB)\n",
      "Downloading ruamel.yaml.clib-0.2.14-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (723 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m723.9/723.9 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading zstandard-0.25.0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: zstandard, ruamel.yaml.clib, lz4, ruamel.yaml, rosbags\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [rosbags]m4/5\u001b[0m [rosbags]aml]clib]\n",
      "\u001b[1A\u001b[2KSuccessfully installed lz4-4.4.5 rosbags-0.9.23 ruamel.yaml-0.18.16 ruamel.yaml.clib-0.2.14 zstandard-0.25.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install rosbags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e08f6711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict \n",
    "from rosbags.highlevel import AnyReader\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a2fb25",
   "metadata": {},
   "source": [
    "## Defining .bag files\n",
    "\n",
    "All data files should be placed in the `../data/SOLAQUA` folder.\n",
    "\n",
    "- `*_data.bag` → contains **sensor data** (ROS bag format).\n",
    "- `*_video.bag` → contains **video images** (ROS bag format).\n",
    "\n",
    "The dataset used is **SOLAQUA**, available from [SINTEF Open Data](https://data.sintef.no/feature/fe-a8f86232-5107-495e-a3dd-a86460eebef6).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0eb7c69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data bag : /cluster/home/henrban/SOLAQUA-UOD/uw_yolov8/data/SOLAQUA/2024-08-20_13-57-42_data.bag\n",
      "Using video bag: /cluster/home/henrban/SOLAQUA-UOD/uw_yolov8/data/SOLAQUA/2024-08-20_13-57-42_video.bag\n",
      "Output folder : /cluster/home/henrban/SOLAQUA-UOD/uw_yolov8/data/SOLAQUA/processed\n"
     ]
    }
   ],
   "source": [
    "# Change these two lines to switch dataset\n",
    "DATA_BAG  = Path(\"../data/SOLAQUA/2024-08-20_13-57-42_data.bag\")   # sensor data\n",
    "VIDEO_BAG = Path(\"../data/SOLAQUA/2024-08-20_13-57-42_video.bag\")  # camera and sonar video\n",
    "\n",
    "# Output folder for extracted frames, videos, sonar arrays, etc.\n",
    "OUT_ROOT = Path(\"../data/SOLAQUA/processed\")\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Using data bag : {DATA_BAG.resolve()}\")\n",
    "print(f\"Using video bag: {VIDEO_BAG.resolve()}\")\n",
    "print(f\"Output folder : {OUT_ROOT.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddad7ffa",
   "metadata": {},
   "source": [
    "## List Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75c4d8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 2024-08-20_13-57-42_data.bag ===\n",
      "TOPIC                                     TYPE                                     COUNT    START(ns)          END(ns)            DURATION(s)  ~HZ\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "/bluerov2/alive                           std_msgs/msg/Float32                       155    1724155067444230600  1724155144060540800       76.616   2.02\n",
      "/bluerov2/armed                           std_msgs/msg/Float32                       155    1724155067237915400  1724155144060590500       76.823   2.02\n",
      "/bluerov2/battery                         messages/msg/BatteryStatus                  72    1724155068909052000  1724155143540579800       74.632   0.96\n",
      "/bluerov2/modes                           joystick/msg/ModeManager2                    1    1724155068085504100  1724155068085504100        0.000   0.00\n",
      "/commanded_thrust                         rospy_tutorials/msg/Floats                1545    1724155067063175400  1724155144255655100       77.192  20.01\n",
      "/controller/x                             messages/msg/MRACOupdate                   679    1724155068444524000  1724155144220882300       75.776   8.96\n",
      "/controller/y                             messages/msg/MRACOupdate                   675    1724155068862606600  1724155144221004400       75.358   8.96\n",
      "/controller/yaw                           messages/msg/PIDState                      669    1724155069521611800  1724155144217863100       74.696   8.96\n",
      "/controller/z                             messages/msg/PIDState                      672    1724155069170983800  1724155144217932600       75.047   8.95\n",
      "/gui/netFollowing_manager                 messages/msg/NetFollowingManager            76    1724155069180896000  1724155144187321900       75.006   1.01\n",
      "/guidance                                 messages/msg/GuidanceManager               697    1724155066472931800  1724155144217597400       77.745   8.97\n",
      "/joystick                                 joystick/msg/Joystick                     1500    1724155069298639700  1724155144250060900       74.951  20.01\n",
      "/joystick/init                            std_msgs/msg/Float32                         1    1724155068508857100  1724155068508857100        0.000   0.00\n",
      "/navigation/plane_approximation           messages/msg/PlaneApproximation            696    1724155066573207700  1724155144216894400       77.644   8.96\n",
      "/navigation/plane_approximation_position  messages/msg/PlaneApproximationPosition    351    1724155067788864900  1724155144228688400       76.440   4.59\n",
      "/rosout                                   rosgraph_msgs/msg/Log                       31    1724155064532995800  1724155144260547700       79.728   0.39\n",
      "/sensor/attitude                          messages/msg/Attitude                     1238    1724155068375587100  1724155144236483400       75.861  16.32\n",
      "/sensor/depth_temperature                 messages/msg/DepthTemperature             1152    1724155069095344100  1724155144250852400       75.156  15.33\n",
      "/sensor/dvl_position                      sensors/msg/DVLPosition                    355    1724155066917293100  1724155144228488400       77.311   4.59\n",
      "/sensor/dvl_velocity                      sensors/msg/DVLVelocity                    704    1724155065682507100  1724155144215914600       78.533   8.96\n",
      "/sensor/imu                               messages/msg/IMU                          1220    1724155069627852800  1724155144222865600       74.595  16.35\n",
      "/sensor/ping360                           sensors/msg/Ping360                        532    1724155069724652400  1724155141028721000       71.304   7.46\n",
      "/sensor/ping360_config                    sensors/msg/Ping360_config_2                 1    1724155068722308600  1724155068722308600        0.000   0.00\n",
      "/sensor/usbl                              sensors/msg/SonardyneUSBL2                  39    1724155067700793300  1724155142843153700       75.142   0.52\n",
      "\n",
      "=== 2024-08-20_13-57-42_video.bag ===\n",
      "TOPIC                                TYPE                             COUNT    START(ns)          END(ns)            DURATION(s)  ~HZ\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "/image/compressed_image/camera_info  sensor_msgs/msg/CameraInfo           1    1724155064784003000  1724155064784003000        0.000   0.00\n",
      "/image/compressed_image/data         sensor_msgs/msg/CompressedImage   1997    1724155065138761300  1724155144977176000       79.838  25.01\n",
      "/sensor/sonoptix_echo/image          sensors/msg/SonoptixECHO          1249    1724155065046873200  1724155144923840200       79.877  15.64\n",
      "/ted/image                           sensor_msgs/msg/CompressedImage   2002    1724155064915286300  1724155144955767400       80.040  25.01\n"
     ]
    }
   ],
   "source": [
    "def human_hz(count, duration_s):\n",
    "    if count == 0 or duration_s <= 0:\n",
    "        return 0.0\n",
    "    return count / duration_s\n",
    "\n",
    "for bag in [DATA_BAG, VIDEO_BAG]:\n",
    "    print(f\"\\n=== {bag.name} ===\")\n",
    "    if not bag.exists():\n",
    "        print(\"  (missing)\")\n",
    "        continue\n",
    "\n",
    "    counts = defaultdict(int)\n",
    "    first_ts = defaultdict(lambda: None)\n",
    "    last_ts  = defaultdict(lambda: None)\n",
    "    types = {}\n",
    "\n",
    "    with AnyReader([bag]) as r:\n",
    "        for c in r.connections:\n",
    "            types[c.topic] = c.msgtype\n",
    "        for conn, ts, _ in r.messages():\n",
    "            t = conn.topic\n",
    "            counts[t] += 1\n",
    "            if first_ts[t] is None or ts < first_ts[t]:\n",
    "                first_ts[t] = ts\n",
    "            if last_ts[t] is None or ts > last_ts[t]:\n",
    "                last_ts[t] = ts\n",
    "\n",
    "    if not counts:\n",
    "        print(\"  (no messages)\")\n",
    "        continue\n",
    "\n",
    "    col_topic = max(len(t) for t in counts.keys())\n",
    "    col_type  = max(len(types.get(t, \"\")) for t in counts.keys())\n",
    "    header = f\"{'TOPIC'.ljust(col_topic)}  {'TYPE'.ljust(col_type)}  COUNT    START(ns)          END(ns)            DURATION(s)  ~HZ\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "\n",
    "    for t in sorted(counts.keys()):\n",
    "        n = counts[t]\n",
    "        t0 = first_ts[t]\n",
    "        t1 = last_ts[t]\n",
    "        dur_s = (t1 - t0) / 1e9 if (t0 is not None and t1 is not None) else 0.0\n",
    "        hz = human_hz(n, dur_s)\n",
    "        print(\n",
    "            f\"{t.ljust(col_topic)}  \"\n",
    "            f\"{types.get(t,'').ljust(col_type)}  \"\n",
    "            f\"{str(n).rjust(5)}    \"\n",
    "            f\"{str(t0).rjust(16)}  \"\n",
    "            f\"{str(t1).rjust(16)}  \"\n",
    "            f\"{dur_s:11.3f}  {hz:5.2f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd355a5",
   "metadata": {},
   "source": [
    "## Extracting data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8832cc",
   "metadata": {},
   "source": [
    "### Extract frames for _video.bag \n",
    "\n",
    "Remeber to handle if _video.bag has compressed and uncomressed images. \n",
    "\n",
    "Remember to handle if we have multiple topics under the same type, we will get flickering effect in video and \"duplicate\" images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79cd3fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Reading 2024-08-20_13-57-42_video.bag\n",
      "[INFO] Saving frames under: ../data/SOLAQUA/processed/2024-08-20_13-57-42/camera\n",
      "[INFO] → Topic '/ted/image' → ../data/SOLAQUA/processed/2024-08-20_13-57-42/camera/ted__image/image_frames\n",
      "[INFO] → Topic '/image/compressed_image/data' → ../data/SOLAQUA/processed/2024-08-20_13-57-42/camera/image__compressed_image__data/image_frames\n",
      "[INFO] [/ted/image] Saved 100 frames …\n",
      "[INFO] [/image/compressed_image/data] Saved 100 frames …\n",
      "[INFO] [/ted/image] Saved 200 frames …\n",
      "[INFO] [/image/compressed_image/data] Saved 200 frames …\n",
      "[INFO] [/ted/image] Saved 300 frames …\n",
      "[INFO] [/image/compressed_image/data] Saved 300 frames …\n",
      "[INFO] [/ted/image] Saved 400 frames …\n",
      "[INFO] [/image/compressed_image/data] Saved 400 frames …\n",
      "[INFO] [/ted/image] Saved 500 frames …\n",
      "[INFO] [/image/compressed_image/data] Saved 500 frames …\n",
      "[INFO] [/ted/image] Saved 600 frames …\n",
      "[INFO] [/image/compressed_image/data] Saved 600 frames …\n",
      "[INFO] [/ted/image] Saved 700 frames …\n",
      "[INFO] [/image/compressed_image/data] Saved 700 frames …\n",
      "[INFO] [/ted/image] Saved 800 frames …\n",
      "[INFO] [/image/compressed_image/data] Saved 800 frames …\n",
      "[INFO] [/ted/image] Saved 900 frames …\n",
      "[INFO] [/image/compressed_image/data] Saved 900 frames …\n",
      "[INFO] [/ted/image] Saved 1000 frames …\n",
      "[INFO] [/image/compressed_image/data] Saved 1000 frames …\n",
      "[INFO] [/ted/image] Saved 1100 frames …\n",
      "[INFO] [/image/compressed_image/data] Saved 1100 frames …\n",
      "[INFO] [/ted/image] Saved 1200 frames …\n",
      "[INFO] [/image/compressed_image/data] Saved 1200 frames …\n",
      "[INFO] [/ted/image] Saved 1300 frames …\n",
      "[INFO] [/image/compressed_image/data] Saved 1300 frames …\n",
      "[INFO] [/ted/image] Saved 1400 frames …\n",
      "[INFO] [/image/compressed_image/data] Saved 1400 frames …\n",
      "[INFO] [/ted/image] Saved 1500 frames …\n",
      "[INFO] [/image/compressed_image/data] Saved 1500 frames …\n",
      "[INFO] [/ted/image] Saved 1600 frames …\n",
      "[INFO] [/image/compressed_image/data] Saved 1600 frames …\n",
      "[INFO] [/ted/image] Saved 1700 frames …\n",
      "[INFO] [/image/compressed_image/data] Saved 1700 frames …\n",
      "[INFO] [/ted/image] Saved 1800 frames …\n",
      "[INFO] [/image/compressed_image/data] Saved 1800 frames …\n",
      "[INFO] [/ted/image] Saved 1900 frames …\n",
      "[INFO] [/image/compressed_image/data] Saved 1900 frames …\n",
      "[INFO] [/ted/image] Saved 2000 frames …\n",
      "\n",
      "[DONE] Per-topic results:\n",
      "  - /image/compressed_image/data → saved:  1997, skipped:     0, dir: ../data/SOLAQUA/processed/2024-08-20_13-57-42/camera/image__compressed_image__data/image_frames\n",
      "  - /ted/image → saved:  2002, skipped:     0, dir: ../data/SOLAQUA/processed/2024-08-20_13-57-42/camera/ted__image/image_frames\n",
      "\n",
      "[TOTAL] Saved 3999 frames across 2 topics.\n"
     ]
    }
   ],
   "source": [
    "# Extract camera frames from the selected VIDEO_BAG\n",
    "# New layout (per-topic):\n",
    "#   ./output/<bag_timestamp>/camera/<topic_sanitized>/image_frames/<topic_sanitized>_<ros_timestamp>.jpg\n",
    "#\n",
    "# - Derives the timestamp folder from the bag (strips \"_video\" suffix).\n",
    "# - Saves frames for each image topic into its own subfolder to avoid interleaving/flicker.\n",
    "# - Handles CompressedImage and common raw Image encodings.\n",
    "# - Adds per-topic stats and progress logs every 100 saved frames.\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Assumes these are already defined in your environment:\n",
    "# VIDEO_BAG: Path to the .bag\n",
    "# OUT_ROOT: base output Path\n",
    "# AnyReader: bag reader (e.g., rosbags, mcap, etc.)\n",
    "\n",
    "# --- Config ---\n",
    "# If you want to include only certain topics, put them here; otherwise leave as None to include all image topics.\n",
    "TOPIC_INCLUDE = None  # e.g., [\"/image/compressed_image/data\", \"/ted/image\"]\n",
    "\n",
    "# If you want to exclude certain topics, list them here (checked after include).\n",
    "TOPIC_EXCLUDE = []    # e.g., [\"/image/compressed_image/camera_info\"]\n",
    "\n",
    "# --- Output scaffolding ---\n",
    "bag_stem = VIDEO_BAG.stem.replace(\"_video\", \"\")\n",
    "RUN_ROOT = OUT_ROOT / bag_stem / \"camera\"\n",
    "RUN_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "assert VIDEO_BAG.exists(), f\"Missing video bag: {VIDEO_BAG}\"\n",
    "\n",
    "print(f\"[INFO] Reading {VIDEO_BAG.name}\")\n",
    "print(f\"[INFO] Saving frames under: {RUN_ROOT}\")\n",
    "\n",
    "def sanitize_topic(topic: str) -> str:\n",
    "    \"\"\"Make a filesystem-safe topic label (stable and readable).\"\"\"\n",
    "    # Strip leading slash, replace remaining slashes with double underscores\n",
    "    # Keep alphanum, underscore and dash, map others to underscore.\n",
    "    base = topic.strip(\"/\")\n",
    "    safe = base.replace(\"/\", \"__\")\n",
    "    safe = \"\".join(ch if (ch.isalnum() or ch in (\"_\", \"-\", \".\", \"__\")) else \"_\" for ch in safe)\n",
    "    return safe or \"topic\"\n",
    "\n",
    "def ensure_topic_dirs(topic: str, cache: dict) -> Path:\n",
    "    \"\"\"Create and cache the per-topic image_frames directory.\"\"\"\n",
    "    if topic not in cache:\n",
    "        safe = sanitize_topic(topic)\n",
    "        topic_dir = RUN_ROOT / safe / \"image_frames\"\n",
    "        topic_dir.mkdir(parents=True, exist_ok=True)\n",
    "        cache[topic] = topic_dir\n",
    "        print(f\"[INFO] → Topic '{topic}' → {topic_dir}\")\n",
    "    return cache[topic]\n",
    "\n",
    "def decode_raw_image(msg):\n",
    "    \"\"\"Decode sensor_msgs/msg/Image to BGR np.ndarray (uint8).\"\"\"\n",
    "    h, w, step = msg.height, msg.width, msg.step\n",
    "    enc = (msg.encoding or \"\").lower()\n",
    "    buf = np.frombuffer(msg.data, dtype=np.uint8)\n",
    "\n",
    "    # Common 8-bit encodings\n",
    "    if enc in (\"bgr8\",):\n",
    "        frame = buf.reshape(h, step)[:, :w*3].reshape(h, w, 3)\n",
    "        return frame\n",
    "    if enc in (\"rgb8\",):\n",
    "        frame = buf.reshape(h, step)[:, :w*3].reshape(h, w, 3)\n",
    "        return cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "    if enc in (\"mono8\", \"8uc1\", \"8uc1c1\", \"mono\"):\n",
    "        frame = buf.reshape(h, step)[:, :w]\n",
    "        return cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)\n",
    "    if enc in (\"yuv422\", \"yuyv\", \"yuyv422\", \"yuv422_yuy2\"):\n",
    "        # 2 bytes per pixel\n",
    "        frame = buf.reshape(h, step)[:, :w*2]\n",
    "        return cv2.cvtColor(frame, cv2.COLOR_YUV2BGR_YUY2)\n",
    "\n",
    "    # Fallback heuristic (can be wrong for Bayer/16-bit)\n",
    "    chans = 3 if (step % w != 0) else max(1, step // w)\n",
    "    try:\n",
    "        raw = buf.reshape(h, step)[:, :w*chans].reshape(h, w, chans)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    if chans == 1:\n",
    "        return cv2.cvtColor(raw, cv2.COLOR_GRAY2BGR)\n",
    "    if enc == \"rgb8\":  # just in case encoding was weirdly reported\n",
    "        return cv2.cvtColor(raw, cv2.COLOR_RGB2BGR)\n",
    "    return raw\n",
    "\n",
    "def save_frame(topic_dir: Path, topic_safe: str, ts_ns: int, frame_bgr: np.ndarray):\n",
    "    \"\"\"Save a BGR frame as JPEG with topic+timestamp-based filename.\"\"\"\n",
    "    out = topic_dir / f\"{topic_safe}_{ts_ns}.jpg\"\n",
    "    cv2.imwrite(str(out), frame_bgr)\n",
    "\n",
    "# --- Main read loop (per-topic saving) ---\n",
    "saved_by_topic = {}\n",
    "skipped_by_topic = {}\n",
    "topic_dirs_cache = {}\n",
    "\n",
    "from contextlib import ExitStack\n",
    "with ExitStack() as stack:\n",
    "    r = stack.enter_context(AnyReader([VIDEO_BAG]))\n",
    "\n",
    "    for i, (conn, ts, raw) in enumerate(r.messages()):\n",
    "        msgtype = conn.msgtype\n",
    "        topic = conn.topic\n",
    "\n",
    "        # Filter for image-like topics only (skip CameraInfo, sonar custom msgs, etc.)\n",
    "        if msgtype not in (\"sensor_msgs/msg/CompressedImage\", \"sensor_msgs/msg/Image\"):\n",
    "            continue\n",
    "\n",
    "        if TOPIC_INCLUDE and topic not in TOPIC_INCLUDE:\n",
    "            continue\n",
    "        if TOPIC_EXCLUDE and topic in TOPIC_EXCLUDE:\n",
    "            continue\n",
    "\n",
    "        topic_dir = ensure_topic_dirs(topic, topic_dirs_cache)\n",
    "        topic_safe = topic_dir.parent.name  # the sanitized topic folder name\n",
    "\n",
    "        # Decode\n",
    "        if msgtype == \"sensor_msgs/msg/CompressedImage\":\n",
    "            msg = r.deserialize(raw, msgtype)\n",
    "            arr = np.frombuffer(msg.data, np.uint8)\n",
    "            frame = cv2.imdecode(arr, cv2.IMREAD_COLOR)\n",
    "        else:  # sensor_msgs/msg/Image\n",
    "            msg = r.deserialize(raw, msgtype)\n",
    "            frame = decode_raw_image(msg)\n",
    "\n",
    "        # Count bookkeeping\n",
    "        if topic not in saved_by_topic:\n",
    "            saved_by_topic[topic] = 0\n",
    "            skipped_by_topic[topic] = 0\n",
    "\n",
    "        if frame is None:\n",
    "            skipped_by_topic[topic] += 1\n",
    "            continue\n",
    "\n",
    "        save_frame(topic_dir, topic_safe, ts, frame)\n",
    "        saved_by_topic[topic] += 1\n",
    "\n",
    "        # Per-topic progress\n",
    "        if saved_by_topic[topic] % 100 == 0:\n",
    "            print(f\"[INFO] [{topic}] Saved {saved_by_topic[topic]} frames …\")\n",
    "\n",
    "# --- Summary ---\n",
    "print(\"\\n[DONE] Per-topic results:\")\n",
    "total_saved = 0\n",
    "total_skipped = 0\n",
    "for t in sorted(saved_by_topic.keys()):\n",
    "    s = saved_by_topic[t]\n",
    "    k = skipped_by_topic.get(t, 0)\n",
    "    total_saved += s\n",
    "    total_skipped += k\n",
    "    safe = sanitize_topic(t)\n",
    "    out_dir = RUN_ROOT / safe / \"image_frames\"\n",
    "    print(f\"  - {t} → saved: {s:5d}, skipped: {k:5d}, dir: {out_dir}\")\n",
    "\n",
    "print(f\"\\n[TOTAL] Saved {total_saved} frames across {len(saved_by_topic)} topics.\")\n",
    "if total_skipped:\n",
    "    print(f\"[WARN] Skipped {total_skipped} frames (decode failures).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a678679f",
   "metadata": {},
   "source": [
    "### Make MP4 for _video.bag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ceaf05ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Writing 1997 frames → ../data/SOLAQUA/processed/2024-08-20_13-57-42/camera/2024-08-20_13-57-42image__compressed_image__data.mp4\n",
      "[INFO] FPS=25.01  size=1280x720\n",
      "[INFO] Wrote 100/1997 frames …\n",
      "[INFO] Wrote 200/1997 frames …\n",
      "[INFO] Wrote 300/1997 frames …\n",
      "[INFO] Wrote 400/1997 frames …\n",
      "[INFO] Wrote 500/1997 frames …\n",
      "[INFO] Wrote 600/1997 frames …\n",
      "[INFO] Wrote 700/1997 frames …\n",
      "[INFO] Wrote 800/1997 frames …\n",
      "[INFO] Wrote 900/1997 frames …\n",
      "[INFO] Wrote 1000/1997 frames …\n",
      "[INFO] Wrote 1100/1997 frames …\n",
      "[INFO] Wrote 1200/1997 frames …\n",
      "[INFO] Wrote 1300/1997 frames …\n",
      "[INFO] Wrote 1400/1997 frames …\n",
      "[INFO] Wrote 1500/1997 frames …\n",
      "[INFO] Wrote 1600/1997 frames …\n",
      "[INFO] Wrote 1700/1997 frames …\n",
      "[INFO] Wrote 1800/1997 frames …\n",
      "[INFO] Wrote 1900/1997 frames …\n",
      "[DONE] MP4 saved: ../data/SOLAQUA/processed/2024-08-20_13-57-42/camera/2024-08-20_13-57-42image__compressed_image__data.mp4  (1997 frames at 25.01 FPS)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import cv2\n",
    "\n",
    "# Build MP4 from frames in ./output/<timestamp>/camera/<topic_safe>/image_frames/\n",
    "# Save as    ./output/<timestamp>/camera/<timestamp>.mp4\n",
    "\n",
    "bag_stem   = VIDEO_BAG.stem.replace(\"_video\", \"\")\n",
    "RUN_ROOT   = OUT_ROOT / bag_stem / \"camera\"\n",
    "\n",
    "# choose the topic you want to render:\n",
    "TOPIC_SAFE = \"image__compressed_image__data\"   # e.g., \"image__compressed_image__data\" or \"ted__image\"\n",
    "FRAMES_DIR = RUN_ROOT / TOPIC_SAFE / \"image_frames\"\n",
    "OUT_MP4    = RUN_ROOT / f\"{bag_stem + TOPIC_SAFE}.mp4\"\n",
    "\n",
    "assert FRAMES_DIR.exists(), f\"Frame folder not found: {FRAMES_DIR}. Extract frames first.\"\n",
    "\n",
    "# files look like: <topic_safe>_<ros_timestamp>.jpg\n",
    "pat = re.compile(rf\"^{re.escape(TOPIC_SAFE)}_(\\d+)\\.jpg$\")\n",
    "def ts_from_name(p: Path) -> int:\n",
    "    m = pat.match(p.name)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "frames = [p for p in FRAMES_DIR.glob(f\"{TOPIC_SAFE}_*.jpg\") if pat.match(p.name)]\n",
    "frames.sort(key=ts_from_name)\n",
    "assert frames, f\"No frames found in {FRAMES_DIR} matching {TOPIC_SAFE}_*.jpg\"\n",
    "\n",
    "# Estimate capture FPS from timestamps (max possible)\n",
    "ts_list = [ts_from_name(p) for p in frames]\n",
    "dur_s = (ts_list[-1] - ts_list[0]) / 1e9 if len(ts_list) > 1 else 0.0\n",
    "fps_est = (len(ts_list) / dur_s) if dur_s > 0 else 25.0\n",
    "FPS = round(fps_est, 2)\n",
    "\n",
    "# Video dimensions from first frame\n",
    "first = cv2.imread(str(frames[0]))\n",
    "assert first is not None, f\"Failed to read first frame: {frames[0]}\"\n",
    "h, w = first.shape[:2]\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # use 'avc1' if available for H.264\n",
    "vw = cv2.VideoWriter(str(OUT_MP4), fourcc, FPS, (w, h))\n",
    "assert vw.isOpened(), \"VideoWriter failed to open. Check codec availability.\"\n",
    "\n",
    "print(f\"[INFO] Writing {len(frames)} frames → {OUT_MP4}\")\n",
    "print(f\"[INFO] FPS={FPS}  size={w}x{h}\")\n",
    "\n",
    "written = 0\n",
    "for i, fp in enumerate(frames, 1):\n",
    "    img = cv2.imread(str(fp))\n",
    "    if img is None:\n",
    "        continue\n",
    "    if img.shape[:2] != (h, w):\n",
    "        img = cv2.resize(img, (w, h), interpolation=cv2.INTER_AREA)\n",
    "    vw.write(img)\n",
    "    written += 1\n",
    "    if written % 100 == 0:\n",
    "        print(f\"[INFO] Wrote {written}/{len(frames)} frames …\")\n",
    "\n",
    "vw.release()\n",
    "print(f\"[DONE] MP4 saved: {OUT_MP4}  ({written} frames at {FPS} FPS)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5b8e26",
   "metadata": {},
   "source": [
    "### Extract raw sonar frames to .npy \n",
    "This is for later!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "349d37b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Reading 2024-08-20_17-22-40_video.bag\n",
      "[INFO] RAW out: output/2024-08-20_17-22-40/echo/raw_frames\n",
      "[INFO] 50 raw saved … shape=1024x256, min..max=0..64\n",
      "[INFO] 100 raw saved … shape=1024x256, min..max=0..64\n",
      "[INFO] 150 raw saved … shape=1024x256, min..max=0..64\n",
      "[INFO] 200 raw saved … shape=1024x256, min..max=0..64\n",
      "[INFO] 250 raw saved … shape=1024x256, min..max=0..64\n",
      "[INFO] 300 raw saved … shape=1024x256, min..max=0..62\n",
      "[INFO] 350 raw saved … shape=1024x256, min..max=0..64\n",
      "[INFO] 400 raw saved … shape=1024x256, min..max=0..63\n",
      "[INFO] 450 raw saved … shape=1024x256, min..max=0..63\n",
      "[INFO] 500 raw saved … shape=1024x256, min..max=0..62\n",
      "[INFO] 550 raw saved … shape=1024x256, min..max=0..62\n",
      "[INFO] 600 raw saved … shape=1024x256, min..max=0..62\n",
      "[INFO] 650 raw saved … shape=1024x256, min..max=0..63\n",
      "[INFO] 700 raw saved … shape=1024x256, min..max=0..62\n",
      "[INFO] 750 raw saved … shape=1024x256, min..max=0..63\n",
      "[DONE] RAW frames: 795  → output/2024-08-20_17-22-40/echo/raw_frames\n"
     ]
    }
   ],
   "source": [
    "# Extract raw SonoptixECHO pings from VIDEO_BAG to .npy (exact float32 arrays)\n",
    "# Output:\n",
    "#   ./output/<timestamp>/echo/raw_frames/sonar_<ros_ts>.npy\n",
    "\n",
    "\n",
    "\n",
    "assert VIDEO_BAG.exists(), f\"Missing video bag: {VIDEO_BAG}\"\n",
    "\n",
    "# Derive <timestamp> folder from VIDEO_BAG (strip \"_video\")\n",
    "bag_stem = VIDEO_BAG.stem.replace(\"_video\", \"\")\n",
    "\n",
    "ECHO_ROOT = OUT_ROOT / bag_stem / \"echo\"\n",
    "RAW_DIR   = ECHO_ROOT / \"raw_frames\"\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "saved_raw = 0\n",
    "skipped   = 0\n",
    "\n",
    "print(f\"[INFO] Reading {VIDEO_BAG.name}\")\n",
    "print(f\"[INFO] RAW out: {RAW_DIR}\")\n",
    "\n",
    "with AnyReader([VIDEO_BAG]) as r:\n",
    "    for i, (conn, ts, raw) in enumerate(r.messages()):\n",
    "        if conn.msgtype != \"sensors/msg/SonoptixECHO\":\n",
    "            continue\n",
    "\n",
    "        msg  = r.deserialize(raw, conn.msgtype)\n",
    "        data = np.asarray(msg.array_data.data, dtype=np.float32)\n",
    "\n",
    "        # Determine H, W from layout (fallback heuristics)\n",
    "        dims = msg.array_data.layout.dim\n",
    "        H = int(dims[0].size) if len(dims) > 0 else 1024\n",
    "        W = int(dims[1].size) if len(dims) > 1 else 256\n",
    "\n",
    "        if data.size != H * W:\n",
    "            if data.size == 1024 * 256:\n",
    "                H, W = 1024, 256\n",
    "            elif data.size == 256 * 1024:\n",
    "                H, W = 256, 1024\n",
    "            else:\n",
    "                print(f\"[WARN] size mismatch: vec={data.size}, layout={H}x{W}; skip ts={ts}\")\n",
    "                skipped += 1\n",
    "                continue\n",
    "\n",
    "        sonar_raw = data.reshape(H, W)\n",
    "        np.save(RAW_DIR / f\"sonar_{ts}.npy\", sonar_raw)\n",
    "        saved_raw += 1\n",
    "\n",
    "        if saved_raw % 50 == 0:\n",
    "            finite = np.isfinite(sonar_raw)\n",
    "            if np.any(finite):\n",
    "                mn = float(np.min(sonar_raw[finite]))\n",
    "                mx = float(np.max(sonar_raw[finite]))\n",
    "                print(f\"[INFO] {saved_raw} raw saved … shape={H}x{W}, min..max={mn:.3g}..{mx:.3g}\")\n",
    "            else:\n",
    "                print(f\"[INFO] {saved_raw} raw saved … (no finite values)\")\n",
    "\n",
    "print(f\"[DONE] RAW frames: {saved_raw}  → {RAW_DIR}\")\n",
    "if skipped:\n",
    "    print(f\"[WARN] Skipped frames: {skipped}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6858730b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Wrote 50 previews …\n",
      "[INFO] Wrote 100 previews …\n",
      "[INFO] Wrote 150 previews …\n",
      "[INFO] Wrote 200 previews …\n",
      "[INFO] Wrote 250 previews …\n",
      "[INFO] Wrote 300 previews …\n",
      "[INFO] Wrote 350 previews …\n",
      "[INFO] Wrote 400 previews …\n",
      "[INFO] Wrote 450 previews …\n",
      "[INFO] Wrote 500 previews …\n",
      "[INFO] Wrote 550 previews …\n",
      "[INFO] Wrote 600 previews …\n",
      "[INFO] Wrote 650 previews …\n",
      "[INFO] Wrote 700 previews …\n",
      "[INFO] Wrote 750 previews …\n",
      "[DONE] Quicklook PNGs: 795 → output/2024-08-20_17-22-40/echo/quicklook\n",
      "[INFO] Preview mode: p01\n"
     ]
    }
   ],
   "source": [
    "# Create preview PNGs from saved sonar .npy frames (visualization only)\n",
    "# Input : ./output/<timestamp>/echo/raw_frames/sonar_<ros_ts>.npy\n",
    "# Output: ./output/<timestamp>/echo/quicklook/sonar_<ros_ts>.png\n",
    "\n",
    "# Use the same timestamp folder as above (from VIDEO_BAG)\n",
    "bag_stem    = VIDEO_BAG.stem.replace(\"_video\", \"\")\n",
    "ECHO_ROOT   = OUT_ROOT / bag_stem / \"echo\"\n",
    "RAW_DIR     = ECHO_ROOT / \"raw_frames\"\n",
    "PREVIEW_DIR = ECHO_ROOT / \"quicklook\"\n",
    "PREVIEW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "assert RAW_DIR.exists(), f\"Raw frames folder not found: {RAW_DIR}\"\n",
    "\n",
    "# --- Preview normalization mode ---\n",
    "# 'clip01': assumes data roughly in [0,1] and clips outside\n",
    "# 'p01'   : per-frame 1st..99th percentile stretch (more legible)\n",
    "PREVIEW_MODE = \"p01\"\n",
    "\n",
    "def preview_u8(frame: np.ndarray) -> np.ndarray:\n",
    "    v = frame.astype(np.float32)\n",
    "    if PREVIEW_MODE == \"clip01\":\n",
    "        v = np.clip(v, 0.0, 1.0)\n",
    "        v = (v * 255.0).astype(np.uint8)\n",
    "    else:\n",
    "        finite = np.isfinite(v)\n",
    "        if not np.any(finite):\n",
    "            return np.zeros_like(v, dtype=np.uint8)\n",
    "        lo, hi = np.percentile(v[finite], [1.0, 99.0])\n",
    "        if hi <= lo:\n",
    "            hi = lo + 1e-6\n",
    "        v = np.clip((v - lo) / (hi - lo), 0.0, 1.0)\n",
    "        v = (v * 255.0).astype(np.uint8)\n",
    "    # Optional transpose for display\n",
    "    return v.T\n",
    "\n",
    "# Sort by ROS timestamp in filename\n",
    "re_ts = re.compile(r\"sonar_(\\d+)\\.npy$\")\n",
    "def npy_key(p: Path):\n",
    "    m = re_ts.search(p.name)\n",
    "    return int(m.group(1)) if m else 0\n",
    "\n",
    "npy_files = sorted(RAW_DIR.glob(\"sonar_*.npy\"), key=npy_key)\n",
    "assert npy_files, f\"No .npy frames found in {RAW_DIR}\"\n",
    "\n",
    "saved_png = 0\n",
    "for i, npy_path in enumerate(npy_files, 1):\n",
    "    arr = np.load(npy_path)\n",
    "    png = preview_u8(arr)\n",
    "    out = PREVIEW_DIR / (npy_path.stem + \".png\")\n",
    "    cv2.imwrite(str(out), png)\n",
    "    saved_png += 1\n",
    "    if saved_png % 50 == 0:\n",
    "        print(f\"[INFO] Wrote {saved_png} previews …\")\n",
    "\n",
    "print(f\"[DONE] Quicklook PNGs: {saved_png} → {PREVIEW_DIR}\")\n",
    "print(f\"[INFO] Preview mode: {PREVIEW_MODE}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
